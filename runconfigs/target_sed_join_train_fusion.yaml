train_data: /apdcephfs/share_1316500/donchaoyang/code2/data/feature_tsd/train.h5
cv_data: /apdcephfs/share_1316500/donchaoyang/code2/data/feature_tsd/validate.h5
test_data: /apdcephfs/share_1316500/donchaoyang/code2/data/feature_tsd/eval.h5
spk_emb_file_path: /apdcephfs/share_1316500/donchaoyang/code2/data/embeddings/spk_embed.128.txt
encoder_path: /apdcephfs/share_1316500/donchaoyang/code2/data/pre_train_model/ft_local/CNN14_emb128_mAP=0.412.pth
CDur_path: /apdcephfs/share_1316500/donchaoyang/code2/experiments/AudioSet_tsd_fusion/CDur_CNN14_fusion/2021-10-26_16-38-10_1cde71c8363811ec9584dd928bf6bf5f/run_model_17_loss=-0.3456.pt
batch_size: 256
num_workers: 16
data_args:
    mode: stratified # Stratified split to train and cv
optimizer: AdamW
label: /apdcephfs/share_1316500/donchaoyang/code2/data/choose_class/strong_eval_choose_psds.tsv
metadata: /apdcephfs/share_1316500/donchaoyang/code2/data/choose_class/mata_eval_choose.tsv
optimizer_args:
    lr: 0.0001
epochs: 100 
model: Join_fusion
model_args: #Currently None, no additional args
    temppool: linear
outputpath: /apdcephfs/share_1316500/donchaoyang/code2/experiments/Audioset_jtsd_attention_pool
transforms: [freqmask, timemask, shift]
shuffle: False
sampler: MinimumOccupancySampler
loss_sed: BCELoss
loss_ce: CELoss
save: one
early_stop: 7
scheduler_args:
    patience: 3
    factor: 0.1
scale: 2
postprocessing: median
pre_train: True
thres: 0.5
dtc_threshold: 0.7
gtc_threshold: 0.7
cttc_threshold: 0.3
alpha_ct: 0.0
alpha_st: 1
max_efpr: 100
experiment_description: In this experiment, we evaluate fusion strategy for joint training.